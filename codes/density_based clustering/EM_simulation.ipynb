{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4OxoMTVaaqb4",
        "outputId": "7f2ed4ea-acf8-4c9f-9b05-573860bb245d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'means': array([5.39011497, 8.68023882]),\n",
              "  'variances': array([3.12379877, 0.56981736]),\n",
              "  'mixing_coefficients': array([0.68545712, 0.31454288]),\n",
              "  'log_likelihood': -119.97995259349143,\n",
              "  'iterations': 100},\n",
              " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Step 1: Data Generation\n",
        "# Simulate 100 flips each for a fair coin (p=0.5) and a biased coin (p=0.8), 10 times each.\n",
        "np.random.seed(42)  # For reproducibility\n",
        "n_flips = 10\n",
        "n_samples = 100\n",
        "fair_coin_flips = np.random.binomial(n_flips, 0.5, n_samples)\n",
        "biased_coin_flips = np.random.binomial(n_flips, 0.8, n_samples)\n",
        "all_flips = np.concatenate((fair_coin_flips, biased_coin_flips))\n",
        "\n",
        "# Step 2: Initialize Parameters\n",
        "mu = np.array([5, 8])  # Initial means\n",
        "sigma_squared = np.array([2.5, 2.5])  # Initial variances\n",
        "pi = np.array([0.5, 0.5])  # Initial mixing coefficients\n",
        "\n",
        "# Step 3 and 4: EM Algorithm\n",
        "tolerance = 1e-6\n",
        "max_iterations = 100\n",
        "n_components = 2\n",
        "n_iterations = 0\n",
        "log_likelihood = 0\n",
        "\n",
        "# EM Algorithm\n",
        "for iteration in range(max_iterations):\n",
        "    n_iterations += 1\n",
        "\n",
        "    # E-step: Calculate responsibilities\n",
        "    responsibilities = np.zeros((n_samples * 2, n_components))\n",
        "    for k in range(n_components):\n",
        "        responsibilities[:, k] = pi[k] * norm.pdf(all_flips, mu[k], np.sqrt(sigma_squared[k]))\n",
        "    responsibilities /= responsibilities.sum(axis=1, keepdims=True)\n",
        "\n",
        "    # M-step: Update parameters\n",
        "    Nk = responsibilities.sum(axis=0)\n",
        "    mu = np.sum(all_flips[:, np.newaxis] * responsibilities, axis=0) / Nk\n",
        "    sigma_squared = np.sum(responsibilities * (all_flips[:, np.newaxis] - mu)**2, axis=0) / Nk\n",
        "    pi = Nk / (n_samples * 2)\n",
        "\n",
        "    # Check for convergence\n",
        "    new_log_likelihood = np.sum(np.log(np.sum(responsibilities * pi, axis=1)))\n",
        "    if np.abs(new_log_likelihood - log_likelihood) < tolerance:\n",
        "        break\n",
        "    log_likelihood = new_log_likelihood\n",
        "\n",
        "# Final parameter values\n",
        "final_parameters = {\n",
        "    'means': mu,\n",
        "    'variances': sigma_squared,\n",
        "    'mixing_coefficients': pi,\n",
        "    'log_likelihood': log_likelihood,\n",
        "    'iterations': n_iterations\n",
        "}\n",
        "\n",
        "# Step 6: Assign Clusters\n",
        "# Using the final parameters, calculate the maximum responsibility to assign clusters\n",
        "cluster_assignments = np.argmax(responsibilities, axis=1)\n",
        "\n",
        "final_parameters, cluster_assignments[:10]  # Show the first 10 assignments as an example\n"
      ]
    }
  ]
}